{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOyiZ8c12Bcbfzv6lCesOIF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byrcewang/DL_SS2H/blob/main/Architecture_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ],
      "metadata": {
        "id": "8C0EzSEZinPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1"
      ],
      "metadata": {
        "id": "eTfP8mbIisL9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6e_Ha9ihWhD",
        "outputId": "a511c317-44b5-40f2-a030-eb0433cecc53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Summary:\n",
            "RNN(\n",
            "  (rnn): RNN(10, 5)\n",
            "  (linear): Linear(in_features=5, out_features=3, bias=True)\n",
            "  (softmax): LogSoftmax(dim=-1)\n",
            ")\n",
            "Total Parameters: 103\n",
            "Trainable Parameters: 103\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchsummary import summary\n",
        "\n",
        "class RNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = torch.nn.RNN(input_size, hidden_size, num_layers)\n",
        "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.unsqueeze(0)\n",
        "        rr, hn = self.rnn(input, hidden)\n",
        "        return self.softmax(self.linear(rr)), hn\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(self.num_layers, 1, self.hidden_size)\n",
        "\n",
        "# Example parameters for the model\n",
        "input_size = 10  # Example input size\n",
        "hidden_size = 5  # Example hidden size\n",
        "output_size = 3  # Example output size\n",
        "num_layers = 1   # Example number of layers\n",
        "\n",
        "model = RNN(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "def model_summary(model):\n",
        "    print(\"Model Summary:\")\n",
        "    print(model)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total Parameters: {total_params}\")\n",
        "    print(f\"Trainable Parameters: {trainable_params}\")\n",
        "\n",
        "print(model_summary(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple RNN layers"
      ],
      "metadata": {
        "id": "c3bTJWNSpk2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchsummary import summary\n",
        "\n",
        "class RNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        # 修改这里来增加RNN层数\n",
        "        self.rnn = torch.nn.RNN(input_size, hidden_size, num_layers)\n",
        "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.unsqueeze(0)\n",
        "        rr, hn = self.rnn(input, hidden)\n",
        "        return self.softmax(self.linear(rr)), hn\n",
        "\n",
        "    def initHidden(self):\n",
        "        # 为每一层RNN初始化隐状态\n",
        "        return torch.zeros(self.num_layers, 1, self.hidden_size)\n",
        "\n",
        "# 示例参数\n",
        "input_size = 10  # 输入尺寸\n",
        "hidden_size = 5  # 隐藏层尺寸\n",
        "output_size = 3  # 输出尺寸\n",
        "num_layers = 3   # RNN层数\n",
        "\n",
        "model = RNN(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "def model_summary(model):\n",
        "    print(\"Model Summary:\")\n",
        "    print(model)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total Parameters: {total_params}\")\n",
        "    print(f\"Trainable Parameters: {trainable_params}\")\n",
        "\n",
        "model_summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjfct3GEqLye",
        "outputId": "7b2452cc-8fe1-4a3b-ef1c-d3e1e3c704f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Summary:\n",
            "RNN(\n",
            "  (rnn): RNN(10, 5, num_layers=3)\n",
            "  (linear): Linear(in_features=5, out_features=3, bias=True)\n",
            "  (softmax): LogSoftmax(dim=-1)\n",
            ")\n",
            "Total Parameters: 223\n",
            "Trainable Parameters: 223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras"
      ],
      "metadata": {
        "id": "4wCXxMzOjBis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2: Semantic Analysis"
      ],
      "metadata": {
        "id": "lpuVAXhDizKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from scipy import stats\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Activation\n",
        "\n",
        "\n",
        "rnn = Sequential()\n",
        "\n",
        "num_words=15000\n",
        "maxlen=130\n",
        "\n",
        "rnn.add(Embedding(num_words, 32, input_length = 25000)) # num_words=15000, X train shape:  (25000,)\n",
        "rnn.add(SimpleRNN(16,input_shape = (num_words, maxlen), return_sequences=False,activation=\"relu\"))\n",
        "rnn.add(Dense(1)) #flatten\n",
        "rnn.add(Activation(\"sigmoid\")) #using sigmoid for binary classification\n",
        "\n",
        "print(rnn.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IiIrmZji3n-",
        "outputId": "6b3f1210-13ef-41e3-b590-762e563f9a58"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 25000, 32)         480000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 16)                784       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 17        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 480801 (1.83 MB)\n",
            "Trainable params: 480801 (1.83 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入必要的库\n",
        "import numpy as np  # 用于数组和矩阵运算\n",
        "import pandas as pd  # 用于数据处理和读取CSV文件等\n",
        "import seaborn as sns  # 用于数据可视化\n",
        "import matplotlib.pyplot as plt  # 用于绘图\n",
        "%matplotlib inline  # 使matplotlib图形在Jupyter笔记本内展示\n",
        "\n",
        "# 导入用于数据处理的库\n",
        "from scipy import stats  # 用于科学计算和技术计算\n",
        "from tensorflow.keras.datasets import imdb  # 从TensorFlow中导入IMDB电影评论数据集\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # 用于序列数据的预处理，如填充\n",
        "from tensorflow.keras.models import Sequential  # 用于构建序列模型\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Activation  # 导入神经网络的不同层\n",
        "\n",
        "# 初始化一个Sequential模型\n",
        "rnn = Sequential()\n",
        "\n",
        "# 设置模型参数\n",
        "num_words = 15000  # 指定词汇表的大小\n",
        "maxlen = 130  # 指定输入序列的最大长度\n",
        "\n",
        "# 添加一个嵌入层\n",
        "rnn.add(Embedding(num_words, 32, input_length=25000))  # num_words=15000，表示使用前15000个最常见的单词\n",
        "# Embedding层将输入的词索引映射为密集的词向量，每个词向量的维度为32，input_length=25000表示输入序列的长度\n",
        "\n",
        "# 添加一个简单的循环神经网络层（Simple RNN）\n",
        "rnn.add(SimpleRNN(16, input_shape=(num_words, maxlen), return_sequences=False, activation=\"relu\"))\n",
        "# SimpleRNN层有16个神经元，input_shape指定输入数据的形状，return_sequences=False表示只返回输出序列的最后一个输出\n",
        "# activation=\"relu\"指定激活函数为ReLU\n",
        "\n",
        "# 添加一个全连接层\n",
        "rnn.add(Dense(1))  # 输出层只有一个神经元，用于最终的预测\n",
        "\n",
        "# 添加一个激活函数层\n",
        "rnn.add(Activation(\"sigmoid\"))  # 使用sigmoid激活函数，适用于二分类问题\n",
        "\n",
        "# 打印模型的摘要\n",
        "print(rnn.summary())  # 打印出模型结构和参数数量等信息\n"
      ],
      "metadata": {
        "id": "8hFSqRTYh4ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple RNN Layers"
      ],
      "metadata": {
        "id": "6CMHF6z0okZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入必要的库\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from scipy import stats\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Activation\n",
        "\n",
        "# 初始化一个Sequential模型\n",
        "rnn = Sequential()\n",
        "\n",
        "# 设置模型参数\n",
        "num_words = 15000  # 指定词汇表的大小\n",
        "maxlen = 130  # 指定输入序列的最大长度\n",
        "\n",
        "# 添加一个嵌入层\n",
        "rnn.add(Embedding(num_words, 32, input_length=maxlen))  # 注意这里input_length应该是单个输入序列的长度，而不是数据集的大小\n",
        "\n",
        "# 添加多个RNN层\n",
        "num_rnn_layers = 3  # 假设我们想添加3个RNN层\n",
        "for i in range(num_rnn_layers):\n",
        "    if i < num_rnn_layers - 1:\n",
        "        # 对于非最后一个RNN层，设置return_sequences=True\n",
        "        rnn.add(SimpleRNN(16, return_sequences=True, activation=\"relu\"))\n",
        "    else:\n",
        "        # 对于最后一个RNN层，设置return_sequences=False\n",
        "        rnn.add(SimpleRNN(16, return_sequences=False, activation=\"relu\"))\n",
        "\n",
        "# 添加一个全连接层\n",
        "rnn.add(Dense(1))\n",
        "\n",
        "# 添加一个激活函数层\n",
        "rnn.add(Activation(\"sigmoid\"))\n",
        "\n",
        "# 打印模型的摘要\n",
        "print(rnn.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44ejMQ5Uopim",
        "outputId": "6f3d166e-e0b4-4c08-a8bf-fc3439b6009c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 130, 32)           480000    \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 130, 16)           784       \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 130, 16)           528       \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 16)                528       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 481857 (1.84 MB)\n",
            "Trainable params: 481857 (1.84 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}